{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from Queue import Queue, Empty\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get list of featured articles and their urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_list_url = 'https://en.wikipedia.org/wiki/Wikipedia:Featured_articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(featured_list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content.decode('utf8'), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero in on the element containing our information.\n",
    "outer_tag = soup.find(id='mw-content-text')\n",
    "table = outer_tag.find('table')\n",
    "tags_tr = table.find_all('tr')\n",
    "tag = tags_tr[3].find('td')\n",
    "# Make a list from all the children of this tag.\n",
    "children = list(tag.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through all the children and determine if it is a main heading, subheading, or link.\n",
    "# Build a list of tuples of type (heading, subheading, relative url, text)\n",
    "links_with_categories = []\n",
    "cur_h2 = ''\n",
    "cur_h3 = ''\n",
    "for c in children:\n",
    "    if c != '\\n':\n",
    "        if c.name == 'h2':\n",
    "            cur_h2 = c.span.text\n",
    "            cur_h3 = ''\n",
    "        elif c.name == 'h3':\n",
    "            cur_h3 = c.span.text\n",
    "        elif c.name == 'p':\n",
    "            links = c.find_all('a')\n",
    "            for link in links:\n",
    "                links_with_categories.append((cur_h2, cur_h3, link['href'], link.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(links_with_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's make a dataframe just to look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(links_with_categories)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[4000:4050]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Scrape the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_article_info(soup):\n",
    "    \"\"\"Takes a soup object representing an article's webpage and extracts information.\n",
    "    Might want to exclude tables and TOC, but taking everything in the article body for right now.\n",
    "    \"\"\"\n",
    "    tag = soup.find(id='mw-content-text')\n",
    "    return tag.get_text(' ', strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = 'https://en.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    try:\n",
    "        while True:\n",
    "            url_tup = queue.get_nowait()\n",
    "            try:\n",
    "                res = requests.get(base + url_tup[2][1:])\n",
    "                tup = url_tup + (get_article_info(BeautifulSoup(res.content.decode('utf8'), 'lxml')),)\n",
    "                with codecs.open('D:/Datasets/Wikipedia Featured Articles 2/{}.txt'.format(url_tup[2].replace('/', '_')[1:]), \n",
    "                                 'w', encoding='utf8') as f:\n",
    "                    for t in tup:\n",
    "                        f.write(t + '\\n')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    except Empty:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pages = []\n",
    "queue = Queue()\n",
    "for tup in links_with_categories:\n",
    "    queue.put(tup)\n",
    "\n",
    "workers = []\n",
    "for i in xrange(100):\n",
    "    t = Thread(target=get_data)\n",
    "    t.start()\n",
    "    workers.append(t)\n",
    "\n",
    "for worker in workers:\n",
    "    worker.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
